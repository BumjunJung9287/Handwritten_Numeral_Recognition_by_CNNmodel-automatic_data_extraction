{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Learning started.\n",
      "Epoch: 0001 cost = 0.431525774\n",
      "Epoch: 0002 cost = 0.105765128\n",
      "Epoch: 0003 cost = 0.076961261\n",
      "Epoch: 0004 cost = 0.061340322\n",
      "Epoch: 0005 cost = 0.053813879\n",
      "Epoch: 0006 cost = 0.046879263\n",
      "Epoch: 0007 cost = 0.041968299\n",
      "Epoch: 0008 cost = 0.041718365\n",
      "Epoch: 0009 cost = 0.037297408\n",
      "Epoch: 0010 cost = 0.031468368\n",
      "Epoch: 0011 cost = 0.031107485\n",
      "Epoch: 0012 cost = 0.031315916\n",
      "Epoch: 0013 cost = 0.027793923\n",
      "Epoch: 0014 cost = 0.029483450\n",
      "Epoch: 0015 cost = 0.025088975\n",
      "Learning Finished!\n",
      "Accuracy: 0.9936\n",
      "Section ended\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "#import pprint\n",
    "tf.reset_default_graph()  \n",
    "'''\n",
    "print(tf.__version__)\n",
    "print(np.__version__)\n",
    "print(cv2.__version__)\n",
    "1.13.1\n",
    "1.16.2\n",
    "4.1.0\n",
    "'''\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot = True)\n",
    "\n",
    "class cell():\n",
    "    sess = tf.Session()\n",
    "    X = tf.placeholder(tf.float32, [None, 784])\n",
    "    X_img = tf.reshape(X, [-1,28,28,1]) # (black/white)\n",
    "    Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "\n",
    "    learning_rate=0.001\n",
    "    training_epochs = 15\n",
    "    batch_size = 100\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "    W1 = tf.Variable(tf.random_normal([3,3,1,32], stddev=0.01))\n",
    "    L1 = tf.nn.conv2d(X_img, W1, strides=[1,1,1,1], padding=\"SAME\")\n",
    "    L1 = tf.nn.relu(L1) \n",
    "    L1 = tf.nn.max_pool(L1, ksize=[1,2,2,1],\n",
    "                           strides=[1,2,2,1], padding=\"SAME\")\n",
    "    L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "\n",
    "    #L2 ImgIn shape=(?,14,14,32)\n",
    "    W2 = tf.Variable(tf.random_normal([3,3,32,64],stddev=0.01))\n",
    "    #Conv -> (?,14,14,64), Pool -> (?,7,7,64)\n",
    "    L2 = tf.nn.conv2d(L1, W2, strides=[1,1,1,1], padding=\"SAME\")\n",
    "    L2 = tf.nn.relu(L2)\n",
    "    L2 = tf.nn.max_pool(L2, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "    L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "\n",
    "    #L3 ImgIn shape=(?,7,7,64)\n",
    "    W3 = tf.Variable(tf.random_normal([3,3,64,128], stddev=0.01))\n",
    "    #Conv=(?,7,7,128), Pool=(?,4,4,128),\n",
    "    #Reshape=(?,4*4*128) <- Flatten them for FC input\n",
    "    L3 = tf.nn.conv2d(L2, W3, strides=[1,1,1,1], padding=\"SAME\")\n",
    "    L3 = tf.nn.relu(L3)\n",
    "    L3 = tf.nn.max_pool(L3, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "    L3 = tf.nn.dropout(L3,keep_prob=keep_prob)\n",
    "\n",
    "    L3 = tf.reshape(L3, [-1, 4*4*128]) #Flatten them for FC input\n",
    "\n",
    "    #FC 4*4*128 inputs -> 625 outputs\n",
    "    W4 = tf.get_variable(\"W4\",shape=[4*4*128,625],\n",
    "                            initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b4 = tf.Variable(tf.random_normal([625]))\n",
    "    L4 = tf.nn.relu(tf.matmul(L3,W4) + b4)\n",
    "    L4 = tf.nn.dropout(L4, keep_prob=keep_prob)\n",
    "\n",
    "    #L5 Final FC 625 inputs -> 10 outputs\n",
    "    W5 = tf.get_variable(\"W5\",shape=[625,10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b5 = tf.Variable(tf.random_normal([10]))\n",
    "    hypothesis = tf.matmul(L4,W5) + b5\n",
    "\n",
    "    #defice cost/loss & optimizer\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=Y))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    print(\"Learning started.\")\n",
    "    #print(\"I should use tensorflow GPU...\")\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            feed_dict = {X:batch_xs, Y:batch_ys, keep_prob:0.7}\n",
    "            c, _, =sess.run([cost, optimizer], feed_dict = feed_dict)\n",
    "            avg_cost += c / total_batch\n",
    "        print(\"Epoch:\",\"%04d\"%(epoch+1), \"cost =\",\"{:.9f}\".format(avg_cost))\n",
    "\n",
    "    print(\"Learning Finished!\")\n",
    "\n",
    "    #Test model and check accuracy\n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis,1), tf.argmax(Y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print(\"Accuracy:\", sess.run(accuracy, feed_dict = {X:mnist.test.images, Y:mnist.test.labels, keep_prob:1}))\n",
    "\n",
    "    def predict(self,xdata):\n",
    "        return self.sess.run(tf.argmax(self.hypothesis,1),feed_dict={self.X:xdata, self.keep_prob:1})\n",
    "# training result\n",
    "'''\n",
    "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
    "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
    "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
    "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
    "Learning started.\n",
    "Epoch: 0001 cost = 0.431525774\n",
    "Epoch: 0002 cost = 0.105765128\n",
    "Epoch: 0003 cost = 0.076961261\n",
    "Epoch: 0004 cost = 0.061340322\n",
    "Epoch: 0005 cost = 0.053813879\n",
    "Epoch: 0006 cost = 0.046879263\n",
    "Epoch: 0007 cost = 0.041968299\n",
    "Epoch: 0008 cost = 0.041718365\n",
    "Epoch: 0009 cost = 0.037297408\n",
    "Epoch: 0010 cost = 0.031468368\n",
    "Epoch: 0011 cost = 0.031107485\n",
    "Epoch: 0012 cost = 0.031315916\n",
    "Epoch: 0013 cost = 0.027793923\n",
    "Epoch: 0014 cost = 0.029483450\n",
    "Epoch: 0015 cost = 0.025088975\n",
    "Learning Finished!\n",
    "Accuracy: 0.9936\n",
    "'''\n",
    "    \n",
    "    \n",
    "    \n",
    "# cell class for predicting the number image data\n",
    "net = cell()\n",
    "\n",
    "def preprocessing1(img):\n",
    "    # This preprocessing is to take the data of the center of the image \n",
    "    # img data I used: img.shape = (480, 640, 3) \n",
    "    img = img[190:290,270:370]\n",
    "    # color -> gray ((100, 100, 3) -> (100,100,1))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Put some blur to make similar data with MNIST data\n",
    "    img = cv2.GaussianBlur(img, (3, 3), 0)\n",
    "    # Change the shape of the data to MNIST data shape\n",
    "    img = cv2.resize(img, (28, 28))\n",
    "    \n",
    "    #debugging using matplotlib.pyplot (you can see what kind of data your taking)\n",
    "    #plt.imshow(img, cmap=\"Greys\", interpolation=\"nearest\")\n",
    "    #plt.show()\n",
    "    \n",
    "    # Use threshold to clearly distinguish the black and white\n",
    "    res, img = cv2.threshold(img, 110 , 255, cv2.THRESH_BINARY)\n",
    "    img = 255 - img\n",
    "    img = img.astype(np.float32)\n",
    "    # scaling the data\n",
    "    img /= 255\n",
    "    # reshape the data to use it as an input of MNIST data model\n",
    "    img = np.array(img).reshape(1,784)\n",
    "    return img\n",
    "\n",
    "def preprocessing2(img):\n",
    "    # color -> gray ((x,x,3) -> (x,x,1))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.GaussianBlur(img, (3, 3), 0)\n",
    "    img = cv2.resize(img, (28, 28))\n",
    "    #debugging using matplotlib.pyplot (you can see what kind of data your taking)\n",
    "    #plt.imshow(img, cmap=\"Greys\", interpolation=\"nearest\")\n",
    "    #plt.show()\n",
    "    \n",
    "    # Use threshold to clearly distinguish the black and white\n",
    "    res, img = cv2.threshold(img, 110 , 255, cv2.THRESH_BINARY)\n",
    "    img = 255 - img\n",
    "    img = img.astype(np.float32)\n",
    "    # scaling the data\n",
    "    img /= 255\n",
    "    # reshape the data to use it as an input of MNIST data model\n",
    "    img = np.array(img).reshape(1,784)\n",
    "    return img\n",
    "\n",
    "# capture the data from camera\n",
    "capture = cv2.VideoCapture(0)\n",
    "# initialize the Window\n",
    "#cv2.namedWindow(\"debug_1\") # This window is for debugging the extracted data using contour method (showing the contour of whole display)\n",
    "cv2.namedWindow(\"predicting number\") # This window will automatically extract the data of number written in the paper and predict it\n",
    "#cv2.namedWindow(\"predicting number of center\") # This window will predict the data of the center\n",
    "\n",
    "while True:\n",
    "    # read the data from capture\n",
    "    ret, frame = capture.read();\n",
    "    \n",
    "    # changing to gray scale\n",
    "    img_gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Threshold Filtering\n",
    "    retval, dst = cv2.threshold(img_gray, 110, 255, cv2.THRESH_BINARY_INV )\n",
    "    # inversion of black and white\n",
    "    dst = cv2.bitwise_not(dst)\n",
    "    retval, dst = cv2.threshold(dst, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    \n",
    "    #extract the contour from the filtered data\n",
    "    contours, hierarchy = cv2.findContours(dst, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # code for debugging using contour\n",
    "    #ret, dst = capture.read();\n",
    "    #dst = cv2.drawContours(dst, contours, -1, (0, 0, 255, 255), 2, cv2.LINE_AA)\n",
    "    #cv2.imshow('debug_1', dst)\n",
    "    \n",
    "    # read the original data \n",
    "    ret, dst = capture.read();\n",
    "\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        # only using contours that have area over than 400 and less than 20000 \n",
    "        if area<400 and 20000>area:\n",
    "            continue\n",
    "        \n",
    "        x,y,w,h = cv2.boundingRect(contour) \n",
    "        a = max(w,h)\n",
    "        # img.shape = (480, 640, 3) \n",
    "        if (a<10 or x+w/2-a*1.3/2<1 or x+w/2+a*1.3/2>479 or y+h/2-a*1.3/2 <1 or y+h/2+a*1.3/2 >639):\n",
    "            continue\n",
    "        # extract range is decided to make the number data to be similar with MNIST data(train data)\n",
    "        img = dst[int(y+h/2-a*1.3/2):int(y+h/2+a*1.3/2),int(x+w/2-a*1.3/2):int(x+w/2+a*1.3/2),:]\n",
    "        img = preprocessing2(img) # img shape => (28,28)\n",
    "        # drawing rectangle around the data that is predicted\n",
    "        dst = cv2.rectangle(dst,(int(x+w/2-a*1.3/2),int(y+h/2-a*1.3/2)),(int(x+w/2+a*1.3/2),int(y+h/2+a*1.3/2)),(0,255,0),2)\n",
    "        # predict the data\n",
    "        pred = net.predict(img)[0]\n",
    "        text = \"number{}\".format(str(pred))\n",
    "        font = cv2.FONT_HERSHEY_PLAIN\n",
    "        font_size = 1\n",
    "        # put the text including the prediction information\n",
    "        cv2.putText(dst,text,(int(x+w/2-a*1.3/2),int(y+h/2+a*1.3/2 +16)),font, font_size,(255,255,0)) \n",
    "        \n",
    "        c = cv2.waitKey(1)\n",
    "        \n",
    "    cv2.imshow('predicting number', dst)\n",
    "    # get the center image (100,100,3), this is for easy checking \n",
    "    #cv2.rectangle(frame,(270,190),(370,290),(0,0,255),3)\n",
    "    #img = preprocessing1(frame)\n",
    "    #pred = net.predict(img)[0]\n",
    "    #text = \"number{}\".format(str(pred))\n",
    "    #font = cv2.FONT_HERSHEY_PLAIN\n",
    "    #font_size = 1\n",
    "    #cv2.putText(frame,text,(370,290),font, font_size,(255,255,0)) \n",
    "            \n",
    "    #cv2.imshow(\"predicting number of center\", frame)\n",
    "    c = cv2.waitKey(1)\n",
    "\n",
    "    if c == 27: # Esc key\n",
    "        print(\"Section ended\")\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
